{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "collapsed": false,
    "name": "cell1",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Trading data pipeline demo - data pipeline setup\n",
    "\n",
    "This notebook sets up the a data pipeline for trading data using Dynamic Tables. \n",
    "\n",
    "In the Packages menu, add the snowflake-snowpark-python package and then select Start to start the notebook session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark.functions import lit, col, upper, split, when, sum, count, count_distinct, avg, min, max\n",
    "import snowflake.snowpark.functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "language": "python",
    "name": "get_snowpark_session"
   },
   "outputs": [],
   "source": [
    "# Get active Snowflake session (no connection setup needed in Snowflake Notebooks)\n",
    "session = get_active_session()\n",
    "\n",
    "print(\"ðŸ”— Connected to Snowflake using active session!\")\n",
    "print(f\"Current database: {session.get_current_database()}\")\n",
    "print(f\"Current schema: {session.get_current_schema()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285a541-af87-4e30-9b6b-1d8d8de1b9d7",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "Now let's use Dynamic Tables to incrementally transform the raw data. Let's start with the USER_PROFILES table. This dynamic table will keep the latest updated record of a user profile by using its USER_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00fd29-9cae-4829-8867-94623251cd23",
   "metadata": {
    "language": "sql",
    "name": "user_profiles_dt"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE DYNAMIC TABLE STAGING.USER_PROFILES_DT\n",
    "TARGET_LAG = DOWNSTREAM\n",
    "WAREHOUSE = TRADING_ANALYTICS_WH\n",
    "INITIALIZE = ON_CREATE\n",
    "AS\n",
    "SELECT * FROM (\n",
    "    SELECT *, ROW_NUMBER() OVER (PARTITION BY USER_ID ORDER BY _LOADED_AT DESC) as row_num\n",
    "    FROM RAW_DATA.USER_PROFILES\n",
    "    \n",
    ") WHERE row_num = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad1e33d-fed3-4cb1-800f-2c57b8f99a71",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "Let's now create another dynamic table to normalise user trades data. In this case, we will use Snowpark Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "language": "python",
    "name": "clean_user_trades_data"
   },
   "outputs": [],
   "source": [
    "# Create staging view for cleaned trades using Snowpark DataFrames\n",
    "# First, get the raw trades data\n",
    "raw_trades_df = session.table(\"RAW_DATA.USER_TRADES\")\n",
    "\n",
    "# Transform the data using Snowpark operations\n",
    "trades_clean_df = raw_trades_df.select(\n",
    "    col(\"trade_id\"),\n",
    "    col(\"user_id\"),\n",
    "    col(\"symbol\"),\n",
    "    upper(col(\"side\")).alias(\"side\"),\n",
    "    col(\"quantity\"),\n",
    "    col(\"price\"),\n",
    "    (col(\"quantity\") * col(\"price\")).alias(\"notional_value\"),\n",
    "    col(\"timestamp\").cast(\"timestamp\").alias(\"trade_timestamp\"),\n",
    "    upper(col(\"status\")).alias(\"status\"),\n",
    "    upper(col(\"exchange\")).alias(\"exchange\"),\n",
    "    upper(col(\"order_type\")).alias(\"order_type\"),\n",
    "    col(\"fees\"),\n",
    "    col(\"settlement_date\").cast(\"date\").alias(\"settlement_date\"),\n",
    "    col(\"_loaded_at\").alias(\"_loaded_at\"),\n",
    "    col(\"_file_name\").alias(\"_file_name\"),\n",
    "    # Derived fields\n",
    "    split(col(\"symbol\"), F.lit(\"-\"))[0].alias(\"base_currency\"),\n",
    "    split(col(\"symbol\"), F.lit(\"-\"))[1].alias(\"quote_currency\"),\n",
    "    F.date_trunc('day', col(\"timestamp\")).alias(\"trade_date\"),\n",
    "    F.hour(col(\"timestamp\")).alias(\"trade_hour\"),\n",
    "    when(col(\"status\") == \"COMPLETED\", 1).otherwise(0).alias(\"is_completed\")\n",
    ").filter(col(\"trade_id\").isNotNull())\n",
    "\n",
    "\n",
    "trades_clean_df.create_or_replace_dynamic_table(\n",
    "    name=\"STAGING.USER_TRADES_DT\",\n",
    "    warehouse=session.get_current_warehouse(),\n",
    "    lag=\"DOWNSTREAM\",\n",
    "    refresh_mode=\"INCREMENTAL\",\n",
    "    initialize=\"ON_CREATE\"\n",
    ")\n",
    "\n",
    "trades_clean_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fbe15-c2b2-4af5-81eb-efeaa8abb4c4",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": [
    "Lastly, an additional dynamic table will create daily metrics, which will be used to create views in the analytics layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "python",
    "name": "dynamic_table_for_trades"
   },
   "outputs": [],
   "source": [
    "daily_metrics_df = session.table('STAGING.USER_TRADES_DT').filter(col(\"IS_COMPLETED\") == 1)\n",
    "\n",
    "# 3. Group by the specified columns and apply aggregations\n",
    "daily_metrics_df = daily_metrics_df.group_by(\n",
    "    col(\"TRADE_DATE\"),\n",
    "    col(\"SYMBOL\"),\n",
    "    col(\"BASE_CURRENCY\"),\n",
    "    col(\"QUOTE_CURRENCY\"),\n",
    "    col(\"EXCHANGE\")\n",
    ").agg(\n",
    "    count(lit(1)).alias(\"TOTAL_TRADES\"), # COUNT(*)\n",
    "    sum(when(col(\"SIDE\") == 'BUY', 1).otherwise(0)).alias(\"BUY_TRADES\"), # COUNT(CASE WHEN side = 'BUY' THEN 1 END)\n",
    "    sum(when(col(\"SIDE\") == 'SELL', 1).otherwise(0)).alias(\"SELL_TRADES\"), # COUNT(CASE WHEN side = 'SELL' THEN 1 END)\n",
    "    # Since we already filtered by IS_COMPLETED = 1, TOTAL_TRADES is effectively COMPLETED_TRADES\n",
    "    # If you still want a separate column for clarity, you can use:\n",
    "    count(when(col(\"IS_COMPLETED\") == 1, 1)).alias(\"COMPLETED_TRADES\"),\n",
    "    sum(col(\"QUANTITY\")).alias(\"TOTAL_VOLUME\"),\n",
    "    sum(col(\"NOTIONAL_VALUE\")).alias(\"TOTAL_NOTIONAL\"),\n",
    "    avg(col(\"PRICE\")).alias(\"AVG_PRICE\"),\n",
    "    min(col(\"PRICE\")).alias(\"MIN_PRICE\"),\n",
    "    max(col(\"PRICE\")).alias(\"MAX_PRICE\"),\n",
    "    sum(col(\"FEES\")).alias(\"TOTAL_FEES\"),\n",
    "    count_distinct(col(\"USER_ID\")).alias(\"UNIQUE_TRADERS\"),\n",
    "    # Volume-weighted average price (VWAP)\n",
    "    (sum(col(\"NOTIONAL_VALUE\")) / sum(col(\"QUANTITY\"))).alias(\"VWAP\")\n",
    ")\n",
    "\n",
    "daily_metrics_df = daily_metrics_df.create_or_replace_dynamic_table(\n",
    "    name=\"DAILY_TRADING_METRICS\",\n",
    "    warehouse=session.get_current_warehouse(),\n",
    "    lag=\"3 minute\",\n",
    "    refresh_mode=\"INCREMENTAL\",\n",
    "    initialize=\"ON_CREATE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "language": "sql",
    "name": "create_analytical_views"
   },
   "outputs": [],
   "source": [
    "-- Create analytics views for the Streamlit dashboard\n",
    "CREATE OR REPLACE VIEW ANALYTICS.TOP_PERFORMING_ASSETS AS\n",
    "SELECT \n",
    "    symbol,\n",
    "    base_currency,\n",
    "    SUM(total_notional) as total_volume,\n",
    "    AVG(avg_price) as avg_price,\n",
    "    MAX(max_price) as high_price,\n",
    "    MIN(min_price) as low_price,\n",
    "    SUM(total_trades) as total_trades,\n",
    "    SUM(unique_traders) as total_unique_traders\n",
    "FROM ANALYTICS.DAILY_TRADING_METRICS\n",
    "GROUP BY symbol, base_currency\n",
    "ORDER BY total_volume DESC;\n",
    "\n",
    "CREATE OR REPLACE VIEW ANALYTICS.USER_TRADING_SUMMARY AS\n",
    "SELECT \n",
    "    t.user_id,\n",
    "    u.first_name || ' ' || u.last_name as full_name,\n",
    "    u.tier,\n",
    "    u.country,\n",
    "    COUNT(*) as total_trades,\n",
    "    SUM(t.notional_value) as total_volume,\n",
    "    AVG(t.notional_value) as avg_trade_size,\n",
    "    COUNT(DISTINCT t.symbol) as unique_symbols\n",
    "FROM STAGING.USER_TRADES_DT t\n",
    "JOIN STAGING.USER_PROFILES_DT u ON t.user_id = u.user_id\n",
    "WHERE t.is_completed = 1\n",
    "GROUP BY t.user_id, u.first_name, u.last_name, u.tier, u.country\n",
    "ORDER BY total_volume DESC;\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "teresa.nascimento@snowflake.com",
   "authorId": "438606446784",
   "authorName": "TNASCIMENTO",
   "lastEditTime": 1751456878929,
   "notebookId": "7ziq652sox6uavmoe6bt",
   "sessionId": "356a92fc-8c41-456e-8370-2bb48f5fbdfe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
