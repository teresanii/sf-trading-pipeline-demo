{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Crypto Broker Analytics - Data Pipeline\n",
        "\n",
        "This notebook sets up the data pipeline for crypto broker analytics using Snowflake Dynamic Tables for incremental processing and transformation.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The pipeline consists of:\n",
        "1. **Raw Data Layer**: CSV files loaded into Snowflake\n",
        "2. **Staging Layer**: Cleaned and standardized data\n",
        "3. **Analytics Layer**: Aggregated and transformed data for analysis\n",
        "4. **Dynamic Tables**: For incremental processing and real-time updates\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "Raw Data (CSV) â†’ Staging Tables â†’ Dynamic Tables â†’ Analytics Views â†’ Streamlit Dashboard\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import snowflake.connector\n",
        "import pandas as pd\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"ðŸ“¦ Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
        "    user=os.getenv('SNOWFLAKE_USER'),\n",
        "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
        "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=os.getenv('SNOWFLAKE_DATABASE', 'CRYPTO_ANALYTICS'),\n",
        "    schema=os.getenv('SNOWFLAKE_SCHEMA', 'RAW_DATA')\n",
        ")\n",
        "\n",
        "cursor = conn.cursor()\n",
        "\n",
        "print(\"ðŸ”— Connected to Snowflake successfully!\")\n",
        "print(f\"Database: {os.getenv('SNOWFLAKE_DATABASE', 'CRYPTO_ANALYTICS')}\")\n",
        "print(f\"Schema: {os.getenv('SNOWFLAKE_SCHEMA', 'RAW_DATA')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create staging schema and dynamic tables for incremental processing\n",
        "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS STAGING\")\n",
        "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS ANALYTICS\")\n",
        "\n",
        "# Create staging view for cleaned trades\n",
        "cursor.execute(\"\"\"\n",
        "    CREATE OR REPLACE VIEW STAGING.TRADES_CLEAN AS\n",
        "    SELECT \n",
        "        trade_id,\n",
        "        user_id,\n",
        "        symbol,\n",
        "        UPPER(side) as side,\n",
        "        quantity,\n",
        "        price,\n",
        "        quantity * price as notional_value,\n",
        "        timestamp::timestamp as trade_timestamp,\n",
        "        UPPER(status) as status,\n",
        "        UPPER(exchange) as exchange,\n",
        "        UPPER(order_type) as order_type,\n",
        "        fees,\n",
        "        settlement_date::date as settlement_date,\n",
        "        _loaded_at,\n",
        "        _file_name,\n",
        "        -- Derived fields\n",
        "        SPLIT_PART(symbol, '-', 1) as base_currency,\n",
        "        SPLIT_PART(symbol, '-', 2) as quote_currency,\n",
        "        DATE(timestamp) as trade_date,\n",
        "        HOUR(timestamp) as trade_hour,\n",
        "        CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END as is_completed\n",
        "    FROM RAW_DATA.CRYPTO_TRADES\n",
        "    WHERE trade_id IS NOT NULL\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Staging schema and views created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dynamic table for daily trading metrics (incremental processing)\n",
        "cursor.execute(\"USE SCHEMA ANALYTICS\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "    CREATE OR REPLACE DYNAMIC TABLE ANALYTICS.DAILY_TRADING_METRICS\n",
        "    TARGET_LAG = '1 minute'\n",
        "    WAREHOUSE = 'COMPUTE_WH'\n",
        "    AS\n",
        "    SELECT \n",
        "        trade_date,\n",
        "        symbol,\n",
        "        base_currency,\n",
        "        quote_currency,\n",
        "        exchange,\n",
        "        COUNT(*) as total_trades,\n",
        "        COUNT(CASE WHEN side = 'BUY' THEN 1 END) as buy_trades,\n",
        "        COUNT(CASE WHEN side = 'SELL' THEN 1 END) as sell_trades,\n",
        "        COUNT(CASE WHEN is_completed = 1 THEN 1 END) as completed_trades,\n",
        "        SUM(quantity) as total_volume,\n",
        "        SUM(notional_value) as total_notional,\n",
        "        AVG(price) as avg_price,\n",
        "        MIN(price) as min_price,\n",
        "        MAX(price) as max_price,\n",
        "        SUM(fees) as total_fees,\n",
        "        COUNT(DISTINCT user_id) as unique_traders,\n",
        "        -- Volume-weighted average price\n",
        "        SUM(notional_value) / SUM(quantity) as vwap\n",
        "    FROM STAGING.TRADES_CLEAN\n",
        "    WHERE is_completed = 1\n",
        "    GROUP BY trade_date, symbol, base_currency, quote_currency, exchange\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Dynamic table DAILY_TRADING_METRICS created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create analytics views for the Streamlit dashboard\n",
        "cursor.execute(\"\"\"\n",
        "    CREATE OR REPLACE VIEW ANALYTICS.TOP_PERFORMING_ASSETS AS\n",
        "    SELECT \n",
        "        symbol,\n",
        "        base_currency,\n",
        "        SUM(total_notional) as total_volume,\n",
        "        AVG(avg_price) as avg_price,\n",
        "        MAX(max_price) as high_price,\n",
        "        MIN(min_price) as low_price,\n",
        "        SUM(total_trades) as total_trades,\n",
        "        SUM(unique_traders) as total_unique_traders\n",
        "    FROM ANALYTICS.DAILY_TRADING_METRICS\n",
        "    GROUP BY symbol, base_currency\n",
        "    ORDER BY total_volume DESC\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "    CREATE OR REPLACE VIEW ANALYTICS.USER_TRADING_SUMMARY AS\n",
        "    SELECT \n",
        "        t.user_id,\n",
        "        u.first_name || ' ' || u.last_name as full_name,\n",
        "        u.tier,\n",
        "        u.country,\n",
        "        COUNT(*) as total_trades,\n",
        "        SUM(t.notional_value) as total_volume,\n",
        "        AVG(t.notional_value) as avg_trade_size,\n",
        "        COUNT(DISTINCT t.symbol) as unique_symbols\n",
        "    FROM STAGING.TRADES_CLEAN t\n",
        "    JOIN RAW_DATA.USER_PROFILES u ON t.user_id = u.user_id\n",
        "    WHERE t.is_completed = 1\n",
        "    GROUP BY t.user_id, u.first_name, u.last_name, u.tier, u.country\n",
        "    ORDER BY total_volume DESC\n",
        "\"\"\")\n",
        "\n",
        "# Test the pipeline with sample data\n",
        "sample_data = pd.read_sql(\"\"\"\n",
        "    SELECT symbol, total_volume, total_trades \n",
        "    FROM ANALYTICS.TOP_PERFORMING_ASSETS \n",
        "    LIMIT 5\n",
        "\"\"\", conn)\n",
        "\n",
        "print(\"âœ… Analytics views created successfully!\")\n",
        "print(\"ðŸ“Š Sample data from pipeline:\")\n",
        "print(sample_data)\n",
        "\n",
        "# Close connection\n",
        "cursor.close()\n",
        "conn.close()\n",
        "print(\"ðŸ”’ Pipeline setup complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
